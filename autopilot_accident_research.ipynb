{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283979ea",
   "metadata": {},
   "source": [
    "## Tesla and Waymo Data Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056e06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fdbe1",
   "metadata": {},
   "source": [
    "### a. Download Tesla & Waymo Accident Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f14786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla data: 594 records\n",
      "Waymo data: 723 records\n"
     ]
    }
   ],
   "source": [
    "def download_tesla_data():\n",
    "    tesla_url = 'https://docs.google.com/spreadsheets/d/1ESnyJ4b7m96OCjs3GSQ6EGF7YOMuv0XV-ROXTYIazTs/export?format=csv'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(tesla_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        from io import StringIO\n",
    "        tesla_df = pd.read_csv(StringIO(response.text), header=1)\n",
    "        tesla_df.columns = tesla_df.columns.str.strip()\n",
    "        return tesla_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Tesla data download failed: {e}\")\n",
    "        raise SystemExit(\"Tesla dataset download failed\")\n",
    "\n",
    "def download_waymo_data():\n",
    "    waymo_url = 'https://storage.googleapis.com/waymo-uploads/files/documents/safety/safety-impact-data/CSV2%20-%20Crashes%20with%20SGO%20ID%20and%20Group%20Membership%20202009-202503-2022benchmark.csv'\n",
    "    \n",
    "    try:        \n",
    "        response = requests.get(waymo_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        from io import StringIO\n",
    "        waymo_df = pd.read_csv(StringIO(response.text))\n",
    "        waymo_df.columns = waymo_df.columns.str.strip()\n",
    "        return waymo_df\n",
    "        \n",
    "    except Exception as e:    \n",
    "        print(f\"Waymo data download failed: {e}\")\n",
    "        raise SystemExit(\"Waymo dataset download failed\")\n",
    "\n",
    "# Download data\n",
    "tesla_df = download_tesla_data()\n",
    "print(f\"Tesla data: {len(tesla_df)} records\")\n",
    "\n",
    "waymo_df = download_waymo_data()\n",
    "print(f\"Waymo data: {len(waymo_df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce87e4c",
   "metadata": {},
   "source": [
    "### b. Data Preprocessing (standardization only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ad5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data standardization...\n",
      "Tesla: 594 records\n",
      "Waymo: 723 records\n",
      "Combined dataset: 1317 records\n",
      "Data standardization complete\n"
     ]
    }
   ],
   "source": [
    "def standardize_datasets():\n",
    "    combined_data = []\n",
    "    \n",
    "    # Tesla data processing\n",
    "    if 'tesla_df' in globals() and len(tesla_df) > 0:\n",
    "        tesla_clean = pd.DataFrame()\n",
    "        tesla_clean['case_id'] = tesla_df['Case #'].astype(str)\n",
    "        tesla_clean['year'] = pd.to_numeric(tesla_df['Year'], errors='coerce').fillna(0).astype(int)\n",
    "        tesla_clean['state'] = tesla_df['State'].fillna('Unknown')\n",
    "        tesla_clean['deaths'] = pd.to_numeric(tesla_df['Deaths'], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        # Calculate total injuries\n",
    "        injury_cols = ['Tesla driver', 'Tesla occupant', 'Other vehicle(s)', 'Cyclists/ Peds']\n",
    "        total_injuries = 0\n",
    "        for col in injury_cols:\n",
    "            if col in tesla_df.columns:\n",
    "                total_injuries += pd.to_numeric(tesla_df[col], errors='coerce').fillna(0)\n",
    "        tesla_clean['injuries'] = total_injuries.astype(int)\n",
    "        \n",
    "        tesla_clean['autopilot'] = tesla_df['Autopilot claimed'].fillna(False)\n",
    "        tesla_clean['source'] = 'Tesla'\n",
    "        \n",
    "        combined_data.append(tesla_clean)\n",
    "        print(f\"Tesla: {len(tesla_clean)} records\")\n",
    "    \n",
    "    # Waymo data processing  \n",
    "    if 'waymo_df' in globals() and len(waymo_df) > 0:\n",
    "        waymo_clean = pd.DataFrame()\n",
    "        waymo_clean['case_id'] = waymo_df['SGO Report ID'].astype(str)\n",
    "        \n",
    "        year_month = waymo_df['Year Month'].astype(str)\n",
    "        waymo_clean['year'] = year_month.str[:4].astype(int)\n",
    "        waymo_clean['state'] = waymo_df['Location'].str.split(',').str[-1].str.strip().fillna('Unknown')\n",
    "        waymo_clean['deaths'] = 0  \n",
    "        \n",
    "        injuries = 0\n",
    "        if 'Is Any-Injury-Reported' in waymo_df.columns:\n",
    "            injuries += waymo_df['Is Any-Injury-Reported'].fillna(False).astype(int)\n",
    "        waymo_clean['injuries'] = injuries\n",
    "        \n",
    "        waymo_clean['autopilot'] = True  \n",
    "        waymo_clean['source'] = 'Waymo'\n",
    "        \n",
    "        combined_data.append(waymo_clean)\n",
    "        print(f\"Waymo: {len(waymo_clean)} records\")\n",
    "    \n",
    "    # Combine datasets\n",
    "    if combined_data:\n",
    "        final_df = pd.concat(combined_data, ignore_index=True)\n",
    "        \n",
    "        final_df['year'] = final_df['year'].clip(2010, 2025)\n",
    "        final_df['deaths'] = final_df['deaths'].clip(0, 20)\n",
    "        final_df['injuries'] = final_df['injuries'].clip(0, 50)\n",
    "        \n",
    "        print(f\"Combined dataset: {len(final_df)} records\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No data to combine\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Run standardization\n",
    "print(\"Starting data standardization...\")\n",
    "standardized_data = standardize_datasets()\n",
    "\n",
    "if len(standardized_data) > 0:\n",
    "    print(\"Data standardization complete\")\n",
    "    globals()['clean_df'] = standardized_data\n",
    "else:\n",
    "    print(\"Failed to standardize data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dce59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1317, 7)\n",
      "Total records: 1317\n",
      "Data sources:\n",
      "  Waymo: 723 records (54.9%)\n",
      "  Tesla: 594 records (45.1%)\n",
      "  No missing values\n",
      "Time range: 2010 to 2025\n",
      "Records by year:\n",
      "  2010: 14\n",
      "  2013: 2\n",
      "  2014: 4\n",
      "  2015: 5\n",
      "  2016: 15\n",
      "  2017: 11\n",
      "  2018: 18\n",
      "  2019: 47\n",
      "  2020: 40\n",
      "  2021: 63\n",
      "  2022: 100\n",
      "  2023: 193\n",
      "  2024: 540\n",
      "  2025: 265\n",
      "Autopilot usage by year:\n",
      "  2010: 0/14.0 cases (0.0%)\n",
      "  2013: 0/2.0 cases (0.0%)\n",
      "  2014: 0/4.0 cases (0.0%)\n",
      "  2015: 0/5.0 cases (0.0%)\n",
      "  2016: 0/15.0 cases (0.0%)\n",
      "  2017: 0/11.0 cases (0.0%)\n",
      "  2018: 0/18.0 cases (0.0%)\n",
      "  2019: 0/47.0 cases (0.0%)\n",
      "  2020: 1/40.0 cases (2.5%)\n",
      "  2021: 4/63.0 cases (6.3%)\n",
      "  2022: 4/100.0 cases (4.0%)\n",
      "  2023: 85/193.0 cases (44.0%)\n",
      "  2024: 429/540.0 cases (79.4%)\n",
      "  2025: 200/265.0 cases (75.5%)\n",
      "Total deaths: 857\n",
      "Total injuries: 1102\n",
      "Average deaths per case: 0.65\n",
      "Average injuries per case: 0.84\n",
      "By data source:\n",
      "  Tesla: 594 records, 857 deaths, 1038 injuries\n",
      "  Waymo: 723 records, 0 deaths, 64 injuries\n",
      "Visualization error: name 'plt' is not defined\n"
     ]
    }
   ],
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "\n",
    "if 'standardized_data' not in globals() or len(standardized_data) == 0:\n",
    "    print(\"No data available. Run preprocessing first.\")\n",
    "else:\n",
    "    print(f\"Dataset shape: {standardized_data.shape}\")\n",
    "\n",
    "def show_basic_info():\n",
    "    print(f\"Total records: {len(standardized_data)}\")\n",
    "    \n",
    "    source_counts = standardized_data['source'].value_counts()\n",
    "    print(f\"Data sources:\")\n",
    "    for source, count in source_counts.items():\n",
    "        percentage = count / len(standardized_data) * 100\n",
    "        print(f\"  {source}: {count} records ({percentage:.1f}%)\")\n",
    "    \n",
    "    missing_counts = standardized_data.isnull().sum()\n",
    "    has_missing = False\n",
    "    for col, missing in missing_counts.items():\n",
    "        if missing > 0:\n",
    "            print(f\"  {col}: {missing} missing\")\n",
    "            has_missing = True\n",
    "    if not has_missing:\n",
    "        print(\"  No missing values\")\n",
    "\n",
    "def analyze_temporal_patterns():\n",
    "    year_counts = standardized_data['year'].value_counts().sort_index()\n",
    "    print(f\"Time range: {year_counts.index.min()} to {year_counts.index.max()}\")\n",
    "    \n",
    "    print(f\"Records by year:\")\n",
    "    for year, count in year_counts.items():\n",
    "        print(f\"  {year}: {count}\")\n",
    "    \n",
    "    if 'autopilot' in standardized_data.columns:\n",
    "        print(f\"Autopilot usage by year:\")\n",
    "        \n",
    "        df_clean = standardized_data.copy()\n",
    "        df_clean['autopilot_bool'] = df_clean['autopilot'].map(lambda x: True if x in [True, 'True', 1, '1'] else False)\n",
    "        \n",
    "        autopilot_yearly = df_clean.groupby('year').agg({\n",
    "            'case_id': 'count',\n",
    "            'autopilot_bool': 'sum'\n",
    "        })\n",
    "        autopilot_yearly['autopilot_rate'] = (autopilot_yearly['autopilot_bool'] / autopilot_yearly['case_id']) * 100\n",
    "        \n",
    "        for year, row in autopilot_yearly.iterrows():\n",
    "            print(f\"  {year}: {int(row['autopilot_bool'])}/{row['case_id']} cases ({row['autopilot_rate']:.1f}%)\")\n",
    "\n",
    "def analyze_safety_outcomes():\n",
    "    total_deaths = standardized_data['deaths'].sum()\n",
    "    total_injuries = standardized_data['injuries'].sum()\n",
    "    \n",
    "    print(f\"Total deaths: {total_deaths}\")\n",
    "    print(f\"Total injuries: {total_injuries}\")\n",
    "    print(f\"Average deaths per case: {standardized_data['deaths'].mean():.2f}\")\n",
    "    print(f\"Average injuries per case: {standardized_data['injuries'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"By data source:\")\n",
    "    for source in standardized_data['source'].unique():\n",
    "        source_data = standardized_data[standardized_data['source'] == source]\n",
    "        \n",
    "        deaths_total = source_data['deaths'].sum()\n",
    "        injuries_total = source_data['injuries'].sum()\n",
    "        record_count = len(source_data)\n",
    "        \n",
    "        print(f\"  {source}: {record_count} records, {deaths_total} deaths, {injuries_total} injuries\")\n",
    "\n",
    "def create_visualizations():\n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('Autonomous Vehicle Safety Data Analysis', fontsize=16)\n",
    "        \n",
    "        # Records by year\n",
    "        year_counts = standardized_data['year'].value_counts().sort_index()\n",
    "        axes[0,0].bar(year_counts.index, year_counts.values, alpha=0.7, color='steelblue')\n",
    "        axes[0,0].set_title('Records by Year')\n",
    "        axes[0,0].set_xlabel('Year')\n",
    "        axes[0,0].set_ylabel('Number of Records')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Data source distribution\n",
    "        source_counts = standardized_data['source'].value_counts()\n",
    "        axes[0,1].pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "        axes[0,1].set_title('Data Source Distribution')\n",
    "        \n",
    "        # Deaths vs injuries\n",
    "        axes[1,0].scatter(standardized_data['deaths'], standardized_data['injuries'], \n",
    "                         alpha=0.6, color='coral')\n",
    "        axes[1,0].set_xlabel('Deaths per Case')\n",
    "        axes[1,0].set_ylabel('Injuries per Case')\n",
    "        axes[1,0].set_title('Deaths vs Injuries Distribution')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Autopilot usage over time\n",
    "        if 'autopilot' in standardized_data.columns:\n",
    "            df_clean = standardized_data.copy()\n",
    "            df_clean['autopilot_bool'] = df_clean['autopilot'].map(lambda x: True if x in [True, 'True', 1, '1'] else False)\n",
    "            autopilot_by_year = df_clean.groupby('year')['autopilot_bool'].mean() * 100\n",
    "            axes[1,1].plot(autopilot_by_year.index, autopilot_by_year.values, \n",
    "                          marker='o', linewidth=2, color='green')\n",
    "            axes[1,1].set_xlabel('Year')\n",
    "            axes[1,1].set_ylabel('Autopilot Usage (%)')\n",
    "            axes[1,1].set_title('Autopilot Usage Trend')\n",
    "            axes[1,1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, 'Autopilot data\\nnot available', \n",
    "                          ha='center', va='center', transform=axes[1,1].transAxes, fontsize=12)\n",
    "            axes[1,1].set_title('Autopilot Usage Trend')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Run EDA\n",
    "if 'standardized_data' in globals() and len(standardized_data) > 0:\n",
    "    show_basic_info()\n",
    "    analyze_temporal_patterns()\n",
    "    analyze_safety_outcomes()\n",
    "    create_visualizations()\n",
    "else:\n",
    "    print(\"No data available for EDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1ebdb",
   "metadata": {},
   "source": [
    "### c. EDA (Exploratory Data Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6147",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
